{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13724613,"sourceType":"datasetVersion","datasetId":8732109}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:00.539172Z","iopub.execute_input":"2025-11-16T16:38:00.539492Z","iopub.status.idle":"2025-11-16T16:38:00.548359Z","shell.execute_reply.started":"2025-11-16T16:38:00.539471Z","shell.execute_reply":"2025-11-16T16:38:00.547246Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"/kaggle/input/indian-liver-patient-ilp-dataset/Indian Liver Patient Dataset (ILPD).csv\n","output_type":"stream"}],"execution_count":147},{"cell_type":"code","source":"!pip install scikit-learn==1.4.2 imbalanced-learn==0.12.2\n!pip install ctgan","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:00.549955Z","iopub.execute_input":"2025-11-16T16:38:00.550276Z","iopub.status.idle":"2025-11-16T16:38:08.999837Z","shell.execute_reply.started":"2025-11-16T16:38:00.550244Z","shell.execute_reply":"2025-11-16T16:38:08.998585Z"},"collapsed":true,"jupyter":{"source_hidden":true,"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn==1.4.2 in /usr/local/lib/python3.11/dist-packages (1.4.2)\nRequirement already satisfied: imbalanced-learn==0.12.2 in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.15.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.4.2) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.5->scikit-learn==1.4.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.5->scikit-learn==1.4.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.5->scikit-learn==1.4.2) (2024.2.0)\nRequirement already satisfied: ctgan in /usr/local/lib/python3.11/dist-packages (0.11.1)\nRequirement already satisfied: numpy>=1.23.3 in /usr/local/lib/python3.11/dist-packages (from ctgan) (1.26.4)\nRequirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from ctgan) (2.2.3)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ctgan) (2.6.0+cu124)\nRequirement already satisfied: tqdm<5,>=4.29 in /usr/local/lib/python3.11/dist-packages (from ctgan) (4.67.1)\nRequirement already satisfied: rdt>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from ctgan) (1.18.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.3->ctgan) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.3->ctgan) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.3->ctgan) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.3->ctgan) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.3->ctgan) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.3->ctgan) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->ctgan) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->ctgan) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->ctgan) (2025.2)\nRequirement already satisfied: scipy>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from rdt>=1.14.0->ctgan) (1.15.3)\nRequirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from rdt>=1.14.0->ctgan) (1.4.2)\nRequirement already satisfied: Faker!=37.11.0,>=17 in /usr/local/lib/python3.11/dist-packages (from rdt>=1.14.0->ctgan) (38.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->ctgan) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->ctgan) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->ctgan) (1.17.0)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt>=1.14.0->ctgan) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt>=1.14.0->ctgan) (3.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->ctgan) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.3->ctgan) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.3->ctgan) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.3->ctgan) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.3->ctgan) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.3->ctgan) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.3->ctgan) (2024.2.0)\n","output_type":"stream"}],"execution_count":148},{"cell_type":"markdown","source":"### **Project Overview**\n\nThis notebook aims to replicate key parts of the paper: “Tabular Data Generation to Improve Classification of Liver Disease Diagnosis” by _Mohammad Alauthman et al._\n\nThe original study evaluated the performance of several machine learning algorithms on the Indian Liver Patient Dataset (ILPD) while examining the impact of two data augmentation strategies: Generative Adversarial Networks (GANs) and the Synthetic Minority Oversampling Technique (SMOTE).\n\nTheir results indicate that K-Nearest Neighbors (KNN) combined with SMOTE achieved the highest overall classification accuracy. More broadly, the study reported that SMOTE consistently outperformed GAN across all augmentation scenarios (NO-AUG, DD-AUG, and TD-AUG).\n\nHowever, the authors also note that GAN-based augmentation provides greater model stability compared to SMOTE, even if its absolute accuracy is lower.\n\n### **Replication Objective**\n\nIn this notebook, I will:\n\n1.  Progressively apply and compare several supervised machine learning algorithms — KNN, Logistic Regression, Decision Tree, SVM, and ANN — on the ILPD dataset.\n2.  Evaluate model performance before and after applying SMOTE to assess the impact of oversampling on classification quality.\n3.  Reproduce and analyze key evaluation metrics, including Accuracy, Precision, Recall, F1-Score, and ROC-AUC, to verify or challenge the findings reported in the original study.","metadata":{}},{"cell_type":"code","source":"path = \"/kaggle/input/indian-liver-patient-ilp-dataset/Indian Liver Patient Dataset (ILPD).csv\"\ndata=pd.read_csv(path)\n\ncols = ['Age','Gender','TB_total_bilirubin', 'DB_Direct_Bilirubin',\n       'Alkphos_Alkaline_Phosphotase', 'Sgpt_Alamine_Aminotransferase',\n       'Sgot_Aspartate_Aminotransferase', 'TP_Total_Protiens', 'ALB_Albumin',\n       'A/G_Ratio','Selector']\ndata.columns = cols\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.002265Z","iopub.execute_input":"2025-11-16T16:38:09.002606Z","iopub.status.idle":"2025-11-16T16:38:09.027326Z","shell.execute_reply.started":"2025-11-16T16:38:09.002569Z","shell.execute_reply":"2025-11-16T16:38:09.026001Z"}},"outputs":[{"execution_count":149,"output_type":"execute_result","data":{"text/plain":"   Age Gender  TB_total_bilirubin  DB_Direct_Bilirubin  \\\n0   62   Male                10.9                  5.5   \n1   62   Male                 7.3                  4.1   \n2   58   Male                 1.0                  0.4   \n3   72   Male                 3.9                  2.0   \n4   46   Male                 1.8                  0.7   \n\n   Alkphos_Alkaline_Phosphotase  Sgpt_Alamine_Aminotransferase  \\\n0                           699                             64   \n1                           490                             60   \n2                           182                             14   \n3                           195                             27   \n4                           208                             19   \n\n   Sgot_Aspartate_Aminotransferase  TP_Total_Protiens  ALB_Albumin  A/G_Ratio  \\\n0                              100                7.5          3.2       0.74   \n1                               68                7.0          3.3       0.89   \n2                               20                6.8          3.4       1.00   \n3                               59                7.3          2.4       0.40   \n4                               14                7.6          4.4       1.30   \n\n   Selector  \n0         1  \n1         1  \n2         1  \n3         1  \n4         1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>TB_total_bilirubin</th>\n      <th>DB_Direct_Bilirubin</th>\n      <th>Alkphos_Alkaline_Phosphotase</th>\n      <th>Sgpt_Alamine_Aminotransferase</th>\n      <th>Sgot_Aspartate_Aminotransferase</th>\n      <th>TP_Total_Protiens</th>\n      <th>ALB_Albumin</th>\n      <th>A/G_Ratio</th>\n      <th>Selector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>10.9</td>\n      <td>5.5</td>\n      <td>699</td>\n      <td>64</td>\n      <td>100</td>\n      <td>7.5</td>\n      <td>3.2</td>\n      <td>0.74</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>7.3</td>\n      <td>4.1</td>\n      <td>490</td>\n      <td>60</td>\n      <td>68</td>\n      <td>7.0</td>\n      <td>3.3</td>\n      <td>0.89</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>58</td>\n      <td>Male</td>\n      <td>1.0</td>\n      <td>0.4</td>\n      <td>182</td>\n      <td>14</td>\n      <td>20</td>\n      <td>6.8</td>\n      <td>3.4</td>\n      <td>1.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>72</td>\n      <td>Male</td>\n      <td>3.9</td>\n      <td>2.0</td>\n      <td>195</td>\n      <td>27</td>\n      <td>59</td>\n      <td>7.3</td>\n      <td>2.4</td>\n      <td>0.40</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>46</td>\n      <td>Male</td>\n      <td>1.8</td>\n      <td>0.7</td>\n      <td>208</td>\n      <td>19</td>\n      <td>14</td>\n      <td>7.6</td>\n      <td>4.4</td>\n      <td>1.30</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":149},{"cell_type":"code","source":"# one hot encode categorical data\ndata = pd.get_dummies(data)\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.028548Z","iopub.execute_input":"2025-11-16T16:38:09.028903Z","iopub.status.idle":"2025-11-16T16:38:09.050810Z","shell.execute_reply.started":"2025-11-16T16:38:09.028873Z","shell.execute_reply":"2025-11-16T16:38:09.049780Z"}},"outputs":[{"execution_count":150,"output_type":"execute_result","data":{"text/plain":"   Age  TB_total_bilirubin  DB_Direct_Bilirubin  Alkphos_Alkaline_Phosphotase  \\\n0   62                10.9                  5.5                           699   \n1   62                 7.3                  4.1                           490   \n2   58                 1.0                  0.4                           182   \n3   72                 3.9                  2.0                           195   \n4   46                 1.8                  0.7                           208   \n\n   Sgpt_Alamine_Aminotransferase  Sgot_Aspartate_Aminotransferase  \\\n0                             64                              100   \n1                             60                               68   \n2                             14                               20   \n3                             27                               59   \n4                             19                               14   \n\n   TP_Total_Protiens  ALB_Albumin  A/G_Ratio  Selector  Gender_Female  \\\n0                7.5          3.2       0.74         1          False   \n1                7.0          3.3       0.89         1          False   \n2                6.8          3.4       1.00         1          False   \n3                7.3          2.4       0.40         1          False   \n4                7.6          4.4       1.30         1          False   \n\n   Gender_Male  \n0         True  \n1         True  \n2         True  \n3         True  \n4         True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>TB_total_bilirubin</th>\n      <th>DB_Direct_Bilirubin</th>\n      <th>Alkphos_Alkaline_Phosphotase</th>\n      <th>Sgpt_Alamine_Aminotransferase</th>\n      <th>Sgot_Aspartate_Aminotransferase</th>\n      <th>TP_Total_Protiens</th>\n      <th>ALB_Albumin</th>\n      <th>A/G_Ratio</th>\n      <th>Selector</th>\n      <th>Gender_Female</th>\n      <th>Gender_Male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>62</td>\n      <td>10.9</td>\n      <td>5.5</td>\n      <td>699</td>\n      <td>64</td>\n      <td>100</td>\n      <td>7.5</td>\n      <td>3.2</td>\n      <td>0.74</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>62</td>\n      <td>7.3</td>\n      <td>4.1</td>\n      <td>490</td>\n      <td>60</td>\n      <td>68</td>\n      <td>7.0</td>\n      <td>3.3</td>\n      <td>0.89</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>58</td>\n      <td>1.0</td>\n      <td>0.4</td>\n      <td>182</td>\n      <td>14</td>\n      <td>20</td>\n      <td>6.8</td>\n      <td>3.4</td>\n      <td>1.00</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>72</td>\n      <td>3.9</td>\n      <td>2.0</td>\n      <td>195</td>\n      <td>27</td>\n      <td>59</td>\n      <td>7.3</td>\n      <td>2.4</td>\n      <td>0.40</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>46</td>\n      <td>1.8</td>\n      <td>0.7</td>\n      <td>208</td>\n      <td>19</td>\n      <td>14</td>\n      <td>7.6</td>\n      <td>4.4</td>\n      <td>1.30</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":150},{"cell_type":"code","source":"# check for missing values \ndata.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.052970Z","iopub.execute_input":"2025-11-16T16:38:09.053238Z","iopub.status.idle":"2025-11-16T16:38:09.072926Z","shell.execute_reply.started":"2025-11-16T16:38:09.053218Z","shell.execute_reply":"2025-11-16T16:38:09.071975Z"}},"outputs":[{"execution_count":151,"output_type":"execute_result","data":{"text/plain":"Age                                0\nTB_total_bilirubin                 0\nDB_Direct_Bilirubin                0\nAlkphos_Alkaline_Phosphotase       0\nSgpt_Alamine_Aminotransferase      0\nSgot_Aspartate_Aminotransferase    0\nTP_Total_Protiens                  0\nALB_Albumin                        0\nA/G_Ratio                          4\nSelector                           0\nGender_Female                      0\nGender_Male                        0\ndtype: int64"},"metadata":{}}],"execution_count":151},{"cell_type":"code","source":"# replace NaN values with mean\ndata['A/G_Ratio'] = data['A/G_Ratio'].fillna(data['A/G_Ratio'].mean())\ndata['A/G_Ratio'].isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.074135Z","iopub.execute_input":"2025-11-16T16:38:09.074461Z","iopub.status.idle":"2025-11-16T16:38:09.094743Z","shell.execute_reply.started":"2025-11-16T16:38:09.074432Z","shell.execute_reply":"2025-11-16T16:38:09.093729Z"}},"outputs":[{"execution_count":152,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":152},{"cell_type":"code","source":"# set y\ny = data.Selector\n\n# Update the columns list post one hot encoding \ncols = data.columns.tolist()\ncols.remove(\"Selector\")\n\n# set X\nfeatures = cols\nX = data[features]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.095799Z","iopub.execute_input":"2025-11-16T16:38:09.096134Z","iopub.status.idle":"2025-11-16T16:38:09.114356Z","shell.execute_reply.started":"2025-11-16T16:38:09.096093Z","shell.execute_reply":"2025-11-16T16:38:09.113253Z"}},"outputs":[],"execution_count":153},{"cell_type":"code","source":"from sklearn.model_selection import cross_validate\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import matthews_corrcoef, make_scorer\n\nilp_model = KNeighborsClassifier()\nmcc_scorer = make_scorer(matthews_corrcoef)\n\n# scoring = ['accuracy', 'precision', 'recall', 'f1', 'mcc']\n\nscoring = {\n    'accuracy': 'accuracy',\n    'recall': 'recall',\n    'precision': 'precision',\n    'f1': 'f1',\n    'mcc': make_scorer(matthews_corrcoef)\n}\n\ncv_results = cross_validate(ilp_model, X, y, cv=10, scoring=scoring)\n\n# Average scores\nfor metric in scoring:\n    print(f\"Average {metric}: {cv_results['test_' + metric].mean():.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.115617Z","iopub.execute_input":"2025-11-16T16:38:09.115928Z","iopub.status.idle":"2025-11-16T16:38:09.321599Z","shell.execute_reply.started":"2025-11-16T16:38:09.115904Z","shell.execute_reply":"2025-11-16T16:38:09.320630Z"}},"outputs":[{"name":"stdout","text":"Average accuracy: 0.649\nAverage recall: 0.785\nAverage precision: 0.739\nAverage f1: 0.759\nAverage mcc: 0.103\n","output_type":"stream"}],"execution_count":154},{"cell_type":"code","source":"# REPORTING THE FINDINGS \n# Create a dataframe with appropriate column names\nsmote_results = pd.DataFrame(columns=[\"case\", \"accuracy\", \"recall\", \"precision\", \"f1\", \"mcc\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.322293Z","iopub.execute_input":"2025-11-16T16:38:09.322535Z","iopub.status.idle":"2025-11-16T16:38:09.328888Z","shell.execute_reply.started":"2025-11-16T16:38:09.322514Z","shell.execute_reply":"2025-11-16T16:38:09.327787Z"}},"outputs":[],"execution_count":155},{"cell_type":"code","source":"# retrieve the for the initial dataset metrics and add them to the df\nmetric_list = [\"UNBALANCED\"]\nfor metric in scoring:\n    metric_list.append(round(cv_results['test_' + metric].mean(), 4))\n\nsmote_results.loc[len(smote_results)] = metric_list\nprint(smote_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.330197Z","iopub.execute_input":"2025-11-16T16:38:09.330554Z","iopub.status.idle":"2025-11-16T16:38:09.357246Z","shell.execute_reply.started":"2025-11-16T16:38:09.330523Z","shell.execute_reply":"2025-11-16T16:38:09.355806Z"}},"outputs":[{"name":"stdout","text":"         case  accuracy  recall  precision      f1     mcc\n0  UNBALANCED    0.6493  0.7852     0.7393  0.7589  0.1028\n","output_type":"stream"}],"execution_count":156},{"cell_type":"markdown","source":"### Augmentation with SMOTE (Synthetic Minority Oversampling Technique - SMOTE)","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nfrom imblearn.over_sampling import SMOTE\n\nprint(\"Before SMOTE:\", Counter(y))\n\n# Apply SMOTE\nsmote = SMOTE(random_state=42)\nX_smote, y_smote = smote.fit_resample(X, y)\n\nprint(\"After SMOTE:\", Counter(y_smote))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.360677Z","iopub.execute_input":"2025-11-16T16:38:09.361085Z","iopub.status.idle":"2025-11-16T16:38:09.385157Z","shell.execute_reply.started":"2025-11-16T16:38:09.361061Z","shell.execute_reply":"2025-11-16T16:38:09.384149Z"}},"outputs":[{"name":"stdout","text":"Before SMOTE: Counter({1: 415, 2: 167})\nAfter SMOTE: Counter({1: 415, 2: 415})\n","output_type":"stream"}],"execution_count":157},{"cell_type":"code","source":"# calculate with augmented data\ncv_results = cross_validate(ilp_model, X_smote, y_smote, cv=10, scoring=scoring)\n\n# retrieve the for the initial dataset metrics and add them to the df\nmetric_list = [\"BAL-AUG\"]\nfor metric in scoring:\n    metric_list.append(round(cv_results['test_' + metric].mean(), 4))\n\nsmote_results.loc[len(smote_results)] = metric_list\nprint(smote_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.386258Z","iopub.execute_input":"2025-11-16T16:38:09.386548Z","iopub.status.idle":"2025-11-16T16:38:09.609729Z","shell.execute_reply.started":"2025-11-16T16:38:09.386524Z","shell.execute_reply":"2025-11-16T16:38:09.608695Z"}},"outputs":[{"name":"stdout","text":"         case  accuracy  recall  precision      f1     mcc\n0  UNBALANCED    0.6493  0.7852     0.7393  0.7589  0.1028\n1     BAL-AUG    0.7506  0.6189     0.8472  0.7061  0.5250\n","output_type":"stream"}],"execution_count":158},{"cell_type":"code","source":"# get current number of rows\ncurrent_count = Counter(y_smote)[1]\ndouble = current_count * 2\ntriple = current_count * 3\nquadrupule = current_count * 4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.610654Z","iopub.execute_input":"2025-11-16T16:38:09.610975Z","iopub.status.idle":"2025-11-16T16:38:09.615863Z","shell.execute_reply.started":"2025-11-16T16:38:09.610945Z","shell.execute_reply":"2025-11-16T16:38:09.614896Z"}},"outputs":[],"execution_count":159},{"cell_type":"code","source":"# DOUBLE THE DATA WITH SMOTE\n# double y with index 1\nsmote_double = SMOTE(sampling_strategy={1: double}, random_state=42)  \nX_double, y_double = smote_double.fit_resample(X_smote, y_smote)\nprint(\"Double SMOTE:\", Counter(y_double))\n\n# normalize index 1 and 2, effectively doubling the data\nsmote_double = SMOTE(random_state=42)\nX_double, y_double = smote_double.fit_resample(X_double, y_double)\nprint(\"Double SMOTE:\", Counter(y_double))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.616937Z","iopub.execute_input":"2025-11-16T16:38:09.617232Z","iopub.status.idle":"2025-11-16T16:38:09.656824Z","shell.execute_reply.started":"2025-11-16T16:38:09.617211Z","shell.execute_reply":"2025-11-16T16:38:09.655875Z"}},"outputs":[{"name":"stdout","text":"Double SMOTE: Counter({1: 830, 2: 415})\nDouble SMOTE: Counter({1: 830, 2: 830})\n","output_type":"stream"}],"execution_count":160},{"cell_type":"code","source":"# calculate with augmented data\ncv_results = cross_validate(ilp_model, X_double, y_double, cv=10, scoring=scoring)\n\n# retrieve the metrics for the dataset augmented 2 fold and add them to the df\nmetric_list = [\"DD-AUG\"]\nfor metric in scoring:\n    metric_list.append(round(cv_results['test_' + metric].mean(), 4))\n\nsmote_results.loc[len(smote_results)] = metric_list\nprint(smote_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.657809Z","iopub.execute_input":"2025-11-16T16:38:09.658057Z","iopub.status.idle":"2025-11-16T16:38:09.928460Z","shell.execute_reply.started":"2025-11-16T16:38:09.658036Z","shell.execute_reply":"2025-11-16T16:38:09.927398Z"}},"outputs":[{"name":"stdout","text":"         case  accuracy  recall  precision      f1     mcc\n0  UNBALANCED    0.6493  0.7852     0.7393  0.7589  0.1028\n1     BAL-AUG    0.7506  0.6189     0.8472  0.7061  0.5250\n2      DD-AUG    0.8813  0.8241     0.9338  0.8729  0.7707\n","output_type":"stream"}],"execution_count":161},{"cell_type":"code","source":"# TRIPLE THE DATA WITH SMOTE\n\n# Triple the data \nsmote_triple = SMOTE(sampling_strategy={1: triple}, random_state=42)  \nX_triple, y_triple = smote_triple.fit_resample(X_smote, y_smote)\n\n# normalize index 1 and 2, effectively doubling the data\nsmote_triple = SMOTE(random_state=42)\nX_triple, y_triple = smote_double.fit_resample(X_triple, y_triple)\nprint(\"Double SMOTE:\", Counter(y_triple))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.929607Z","iopub.execute_input":"2025-11-16T16:38:09.929896Z","iopub.status.idle":"2025-11-16T16:38:09.957937Z","shell.execute_reply.started":"2025-11-16T16:38:09.929867Z","shell.execute_reply":"2025-11-16T16:38:09.956873Z"}},"outputs":[{"name":"stdout","text":"Double SMOTE: Counter({1: 1245, 2: 1245})\n","output_type":"stream"}],"execution_count":162},{"cell_type":"code","source":"# calculate with augmented data\ncv_results = cross_validate(ilp_model, X_triple, y_triple, cv=10, scoring=scoring, return_train_score=True)\nprint(\"Training mcc:\", cv_results['train_mcc'].mean())\nprint(\"Validation mcc:\", cv_results['test_mcc'].mean())\n\n# retrieve the metrics for the dataset augmented 3 fold and add them to the df\nmetric_list = [\"TD-AUG\"]\nfor metric in scoring:\n    metric_list.append(round(cv_results['test_' + metric].mean(), 4))\n\nsmote_results.loc[len(smote_results)] = metric_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:09.958858Z","iopub.execute_input":"2025-11-16T16:38:09.959115Z","iopub.status.idle":"2025-11-16T16:38:11.494875Z","shell.execute_reply.started":"2025-11-16T16:38:09.959086Z","shell.execute_reply":"2025-11-16T16:38:11.494058Z"}},"outputs":[{"name":"stdout","text":"Training mcc: 0.9107952781201423\nValidation mcc: 0.8517600284243919\n","output_type":"stream"}],"execution_count":163},{"cell_type":"code","source":"# QUADRUPULE THE DATA WITH SMOTE\n\n# Quadrupul data \nsmote_quad = SMOTE(sampling_strategy={1: quadrupule}, random_state=42)  \nX_quad, y_quad = smote_quad.fit_resample(X_smote, y_smote)\n\n# normalize index 1 and 2, effectively Quadrupling the data\nsmote_quad = SMOTE(random_state=42)\nX_quad, y_quad = smote_quad.fit_resample(X_quad, y_quad)\n\n# calculate with augmented data\ncv_results = cross_validate(ilp_model, X_quad, y_quad, cv=10, scoring=scoring, return_train_score=True)\n\n# retrieve the metrics for the dataset augmented 4x and add them to the df\nmetric_list = [\"QD-AUG\"]\nfor metric in scoring:\n    metric_list.append(round(cv_results['test_' + metric].mean(), 4))\n\nsmote_results.loc[len(smote_results)] = metric_list\n\n\n# Compare traning and validation mcc to check for overfitting \nprint(\"Training mcc:\", cv_results['train_mcc'].mean())\nprint(\"Validation mcc:\", cv_results['test_mcc'].mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:11.495952Z","iopub.execute_input":"2025-11-16T16:38:11.496213Z","iopub.status.idle":"2025-11-16T16:38:13.487408Z","shell.execute_reply.started":"2025-11-16T16:38:11.496190Z","shell.execute_reply":"2025-11-16T16:38:13.486454Z"}},"outputs":[{"name":"stdout","text":"Training mcc: 0.9402856652791985\nValidation mcc: 0.9017548380620644\n","output_type":"stream"}],"execution_count":164},{"cell_type":"markdown","source":"#","metadata":{}},{"cell_type":"code","source":"from tabulate import tabulate\nprint(tabulate(smote_results, headers=\"keys\", tablefmt=\"psql\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:13.488394Z","iopub.execute_input":"2025-11-16T16:38:13.488650Z","iopub.status.idle":"2025-11-16T16:38:13.495295Z","shell.execute_reply.started":"2025-11-16T16:38:13.488630Z","shell.execute_reply":"2025-11-16T16:38:13.493963Z"}},"outputs":[{"name":"stdout","text":"+----+------------+------------+----------+-------------+--------+--------+\n|    | case       |   accuracy |   recall |   precision |     f1 |    mcc |\n|----+------------+------------+----------+-------------+--------+--------|\n|  0 | UNBALANCED |     0.6493 |   0.7852 |      0.7393 | 0.7589 | 0.1028 |\n|  1 | BAL-AUG    |     0.7506 |   0.6189 |      0.8472 | 0.7061 | 0.525  |\n|  2 | DD-AUG     |     0.8813 |   0.8241 |      0.9338 | 0.8729 | 0.7707 |\n|  3 | TD-AUG     |     0.9241 |   0.8933 |      0.9538 | 0.9213 | 0.8518 |\n|  4 | QD-AUG     |     0.95   |   0.9265 |      0.9728 | 0.9486 | 0.9018 |\n+----+------------+------------+----------+-------------+--------+--------+\n","output_type":"stream"}],"execution_count":165},{"cell_type":"markdown","source":"### Augmentation with CTGAN (Conditional Tabular Generative Adversarial Network)","metadata":{}},{"cell_type":"code","source":"from ctgan import CTGAN\nimport torch\nimport numpy as np\nimport random\n\n# Set seeds for reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Initialize and train CTGAN\nctgan = CTGAN(epochs=400)\nctgan.fit(data)\n\n# We already know that there is an imbalane of 248 (415-248)\nsynthetic_minority = ctgan.sample(248, {'Selector': 2})\n\n# combine both the original and synthetic data sets \nbalanced_data = pd.concat([data, synthetic_minority])\n\n\n# generate 4x the data and select accordingly - I think its best to just generate all the data i need at once and then select them accordingly \n\nlen_balanced = len(balanced_data)\nnumber_to_generate = (len(balanced_data) * 4) - len_balanced\ngenerated_difference = ctgan.sample(number_to_generate)\n\n# combine and select \nquad_data = pd.concat([balanced_data, generated_difference])\ndouble_data = quad_data.head(len_balanced * 2)\ntripple_data = quad_data.head(len_balanced * 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:13.496288Z","iopub.execute_input":"2025-11-16T16:38:13.496594Z","iopub.status.idle":"2025-11-16T16:38:33.459465Z","shell.execute_reply.started":"2025-11-16T16:38:13.496541Z","shell.execute_reply":"2025-11-16T16:38:33.458581Z"}},"outputs":[],"execution_count":166},{"cell_type":"code","source":"# BALANCED DATA \n\n# set y\ny = balanced_data.Selector\n\n# set z \ncols = balanced_data.columns.tolist()\ncols.remove(\"Selector\")\nfeatures = cols\nX = balanced_data[features]\n\n# Create a dataframe with appropriate column names\ngan_results = pd.DataFrame(columns=[\"case\", \"accuracy\", \"recall\", \"precision\", \"f1\", \"mcc\"])\n\n# calculate with augmented data\ncv_results = cross_validate(ilp_model, X, y, cv=10, scoring=scoring, return_train_score=True)\n\n# retrieve the metrics for the balanced dataset and add them to the results df\nmetric_list = [\"BAL-AUG\"]\nfor metric in scoring:\n    metric_list.append(round(cv_results['test_' + metric].mean(), 4))\n\ngan_results.loc[len(gan_results)] = metric_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:33.460460Z","iopub.execute_input":"2025-11-16T16:38:33.460749Z","iopub.status.idle":"2025-11-16T16:38:34.176645Z","shell.execute_reply.started":"2025-11-16T16:38:33.460727Z","shell.execute_reply":"2025-11-16T16:38:34.175545Z"}},"outputs":[],"execution_count":167},{"cell_type":"code","source":"# 2x DATA \n\n# set y\ny = double_data.Selector\n\n# set z \nfeatures = cols\nX = double_data[features]\n\n# calculate with augmented data\ncv_results = cross_validate(ilp_model, X, y, cv=10, scoring=scoring, return_train_score=True)\n\n# retrieve the metrics for the dataset and add them to the results df\nmetric_list = [\"DD-AUG\"]\nfor metric in scoring:\n    metric_list.append(round(cv_results['test_' + metric].mean(), 4))\n\ngan_results.loc[len(gan_results)] = metric_list\n\n\n# Compare traning and validation mcc to check for overfitting \nprint(\"Training mcc:\", cv_results['train_mcc'].mean())\nprint(\"Validation mcc:\", cv_results['test_mcc'].mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:34.177889Z","iopub.execute_input":"2025-11-16T16:38:34.178187Z","iopub.status.idle":"2025-11-16T16:38:35.330533Z","shell.execute_reply.started":"2025-11-16T16:38:34.178163Z","shell.execute_reply":"2025-11-16T16:38:35.329661Z"}},"outputs":[{"name":"stdout","text":"Training mcc: 0.38563513654292686\nValidation mcc: 0.08839992228494498\n","output_type":"stream"}],"execution_count":168},{"cell_type":"code","source":"# 3x DATA \n\n# set y\ny = tripple_data.Selector\n\n# set z \nfeatures = cols\nX = tripple_data[features]\n\n# calculate with augmented data\ncv_results = cross_validate(ilp_model, X, y, cv=10, scoring=scoring, return_train_score=True)\n\n# retrieve the metrics for the dataset and add them to the results df\nmetric_list = [\"TD-AUG\"]\nfor metric in scoring:\n    metric_list.append(round(cv_results['test_' + metric].mean(), 4))\n\ngan_results.loc[len(gan_results)] = metric_list\n\n\n# Compare traning and validation mcc to check for overfitting \nprint(\"Training mcc:\", cv_results['train_mcc'].mean())\nprint(\"Validation mcc:\", cv_results['test_mcc'].mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:35.331547Z","iopub.execute_input":"2025-11-16T16:38:35.331889Z","iopub.status.idle":"2025-11-16T16:38:36.922924Z","shell.execute_reply.started":"2025-11-16T16:38:35.331864Z","shell.execute_reply":"2025-11-16T16:38:36.921997Z"}},"outputs":[{"name":"stdout","text":"Training mcc: 0.3329808205871804\nValidation mcc: 0.11829541874465996\n","output_type":"stream"}],"execution_count":169},{"cell_type":"code","source":"# 4x DATA \n\n# set y\ny = quad_data.Selector\n\n# set z \nfeatures = cols\nX = quad_data[features]\n\n# calculate with augmented data\ncv_results = cross_validate(ilp_model, X, y, cv=10, scoring=scoring, return_train_score=True)\n\n# retrieve the metrics for the dataset and add them to the results df\nmetric_list = [\"QD-AUG\"]\nfor metric in scoring:\n    metric_list.append(round(cv_results['test_' + metric].mean(), 4))\n\ngan_results.loc[len(gan_results)] = metric_list\n\n\n# Compare traning and validation mcc to check for overfitting \nprint(\"Training mcc:\", cv_results['train_mcc'].mean())\nprint(\"Validation mcc:\", cv_results['test_mcc'].mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:36.923983Z","iopub.execute_input":"2025-11-16T16:38:36.924306Z","iopub.status.idle":"2025-11-16T16:38:38.953507Z","shell.execute_reply.started":"2025-11-16T16:38:36.924274Z","shell.execute_reply":"2025-11-16T16:38:38.952401Z"}},"outputs":[{"name":"stdout","text":"Training mcc: 0.3208790690491784\nValidation mcc: 0.05922492380266385\n","output_type":"stream"}],"execution_count":170},{"cell_type":"code","source":"print(tabulate(gan_results, headers=\"keys\", tablefmt=\"psql\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-16T16:38:38.954508Z","iopub.execute_input":"2025-11-16T16:38:38.954858Z","iopub.status.idle":"2025-11-16T16:38:38.960657Z","shell.execute_reply.started":"2025-11-16T16:38:38.954829Z","shell.execute_reply":"2025-11-16T16:38:38.959878Z"}},"outputs":[{"name":"stdout","text":"+----+---------+------------+----------+-------------+--------+--------+\n|    | case    |   accuracy |   recall |   precision |     f1 |    mcc |\n|----+---------+------------+----------+-------------+--------+--------|\n|  0 | BAL-AUG |     0.7169 |   0.8661 |      0.7793 | 0.8192 | 0.1739 |\n|  1 | DD-AUG  |     0.7783 |   0.9203 |      0.8278 | 0.8696 | 0.0884 |\n|  2 | TD-AUG  |     0.8096 |   0.9417 |      0.8481 | 0.8912 | 0.1183 |\n|  3 | QD-AUG  |     0.809  |   0.9465 |      0.8453 | 0.8916 | 0.0592 |\n+----+---------+------------+----------+-------------+--------+--------+\n","output_type":"stream"}],"execution_count":171},{"cell_type":"markdown","source":"## Dev Notes\n### 15-11-25, 3:00\nI have been able to apply KNN to the ILP dataset and with an accuracy of 0.67 and precision of 0.80, however this is without cross validation or data augmentation \n\nOther Metrics:\n- Accuracy: 0.667\n- Precision: 0.802\n- Recall: 0.739\n- F1-score: 0.769\n- Matthews Correlation Coefficient: 0.175\n- Confusion Matrix:\n     [[65 23]\n     [16 13]]\n\n### 15-11-25, 3:10\nI tried scaling with StandardScalar but it resulted in sliglty worse metrics so going I would not be proceeding with it going forward \nMetrics\n- Accuracy: 0.658\n- Precision: 0.816\n- Recall: 0.705\n- F1-score: 0.756\n- Matthews Correlation Coefficient: 0.201\n- Confusion Matrix:\n     [[62 26]\n     [14 15]]\n\n\n### 15-11-25. 17:30\nAdded 10 fold cross validation, there was a drop in precision but a rise in the MCC, change in other metrics were marginal at best \nMetrics\n- Average accuracy: 0.649\n- Average precision: 0.739\n- Average recall: 0.785\n- Average f1: 0.759\n- Average mcc: 0.103\n\nNext Id be Implementing SMOTE\n\n### 16-11-25. 11:14 \nI initially augmented the imbalanced dataset using SMOTE to equalize the number of samples for both outcomes — disease present and disease absent — bringing each class to 415 samples. This led to an increase of at least 5% in all evaluation metrics except recall, which dropped from 0.7 to 0.6. Conversely, the Matthews Correlation Coefficient (MCC) showed the greatest improvement, increasing from 0.1 to 0.5.\nAt this point, although accuracy, recall, precision, and F1-score were above average, they were still lower than the results reported in the original paper.\n\nAfter progressively increasing SMOTE oversampling up to 4×, performance improved substantially (accuracy 95%, MCC 0.90) with only a 4% train-validation MCC gap, suggesting limited overfitting; however, because SMOTE produces synthetic interpolated samples, I will validate performance on a completely external dataset to ensure true generalizability..\n\nI also included MCC as one of the evaluation metrics — although it was mentioned in the paper, it was not originally used — because it incorporates all values of the confusion matrix (TP, FP, TN, FN) and provides a more reliable measure of performance on imbalanced datasets.\n\nNext: looking into augmentation with CTGAN\n\n### 16-11-25. 17:26\nImplemended CTGAN with variying results. Each time the model is fit to the data, it generates differnet data so, so reproducability is low. \n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}